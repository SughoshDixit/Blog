---
Id: 1027
Title: "Day 27: Quantile Stability, Ties, and Small Samples"
Author: Sughosh P Dixit
Date: "2025-11-27"
Tags: Data Science Quantiles ECDF Interpolation Ties Small Samples Statistics Percentiles
Topic: Data Science
Abstract: "Master practical considerations for computing empirical quantiles. Understand how ties, discrete samples, and different interpolation schemes affect quantile estimates and threshold repeatability."
HeaderImage: /DS-27/quantile_stability_intro.png
isPublished: true
---

# **Day 27: Quantile Stability, Ties, and Small Samples**

<p style={{fontStyle: 'italic', color: '#666', marginTop: '1rem', textAlign: 'center'}}>Navigate the practical challenges of quantile estimation with ties, small samples, and multiple interpolation methods.</p>

<p style={{fontStyle: 'italic', color: '#666', margin: '1rem 0 2rem', textAlign: 'center'}}>When computing percentile thresholds from real data, practical challenges emerge: ties in the data, discrete values, small sample sizes, and different interpolation methods can all affect results.</p>

>  **Note:** This article uses technical terms and abbreviations. For definitions, check out the [Key Terms & Glossary](/key) page.

---

## The Problem: Quantiles in Practice
**Scenario:** You're computing the 90th percentile threshold from transaction data.

**Challenges:**
1. **Ties:** Multiple transactions have the same value
2. **Discrete data:** Values are integers (counts) or categorical
3. **Small samples:** Only 50 observations available
4. **Interpolation:** Different methods give different answers!

**Question:** How do you get stable, repeatable quantile estimates?

---

## The Empirical CDF (ECDF)
### Definition
The **empirical cumulative distribution function** gives the proportion of observations ≤ x:

```
F̂_n(x) = (1/n) × |{i : X_i ≤ x}|
```

**Properties:**
- Step function (jumps at data points)
- F̂_n(x) ∈ [0, 1]
- F̂_n(-∞) = 0, F̂_n(∞) = 1

### ECDF with Ties
**With ties:** Multiple observations at the same value create larger jumps.

**Example:**
```
Data: [1, 2, 2, 2, 3, 4, 5]  (n = 7)

ECDF:
F̂(1) = 1/7 = 0.143
F̂(2) = 4/7 = 0.571  (3 values = 2, plus 1 below)
F̂(3) = 5/7 = 0.714
F̂(4) = 6/7 = 0.857
F̂(5) = 7/7 = 1.000
```

**Visual Example:**

<div style={{marginTop: '2rem', marginBottom: '2rem'}}>
<img src="/DS-27/ecdf_with_ties.png" alt="ECDF with Ties" style={{maxWidth: '100%', height: 'auto', display: 'block', margin: '0 auto', borderRadius: '8px'}} />

---

## Quantile Definition: Multiple Methods
### The Quantile Inverse Problem
**Goal:** Find x such that F̂_n(x) = p

**Problem:** ECDF is a step function—F̂_n(x) = p may have:
- No solution (p falls in a gap)
- Infinite solutions (p falls on a flat step)

### Interpolation Schemes
**There are at least 9 different quantile definitions!**

**Common methods:**

**Type 1: Inverse of ECDF (closest observation)**
```
Q(p) = X_(⌈np⌉)
```

**Type 6: Linear interpolation (Excel)**
```
Q(p) = X_(j) + (X_(j+1) - X_(j)) × (np + 0.5 - j)
where j = ⌊np + 0.5⌋
```

**Type 7: Linear interpolation (R/Python default)**
```
Q(p) = X_(j) + (X_(j+1) - X_(j)) × (np + 1 - p - j)
where j = ⌊(n-1)p + 1⌋
```

### Why It Matters
**Example: n = 10, find 90th percentile**

Data: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

<table>
<thead>
<tr>
<th>Method</th>
<th>Formula</th>
<th>Result</th>
</tr>
</thead>
<tbody>
<tr>
<td>Type 1</td>
<td>X_(⌈9⌉) = X_9</td>
<td><strong>9</strong></td>
</tr>
<tr>
<td>Type 6</td>
<td>Interpolate</td>
<td><strong>9.05</strong></td>
</tr>
<tr>
<td>Type 7</td>
<td>Interpolate</td>
<td><strong>9.1</strong></td>
</tr>
</tbody>
</table>

**Visual Example:**

<img src="/DS-27/interpolation_methods.png" alt="Interpolation Methods" style={{maxWidth: '100%', height: 'auto', display: 'block', margin: '1.5rem auto', borderRadius: '8px'}} />

---

## Ties: The Plateau Problem
### What Happens with Ties?
When multiple observations have the same value, the ECDF has a **flat plateau**.

**Problem:** The quantile is **non-unique** at the plateau level.

### Example with Ties
**Data:** [10, 20, 20, 20, 20, 30, 40, 50] (n = 8)

```
ECDF:
F̂(10) = 1/8 = 0.125
F̂(20) = 5/8 = 0.625  ← Plateau from 0.125 to 0.625
F̂(30) = 6/8 = 0.750
F̂(40) = 7/8 = 0.875
F̂(50) = 8/8 = 1.000
```

**What is the 50th percentile?**
- F̂(20) = 0.625 > 0.50
- F̂(10) = 0.125 < 0.50
- Answer: 20 (but could argue for values between 10 and 20)

### Handling Ties
**Strategies:**
1. **Left-continuous:** Q(p) = inf&#123;x : F̂(x) ≥ p&#125;
2. **Right-continuous:** Q(p) = inf&#123;x : F̂(x) &gt; p&#125;
3. **Midpoint:** Average of left and right
4. **Random jitter:** Add small noise to break ties

**Visual Example:**

<img src="/DS-27/tie_blocks.png" alt="Tie Blocks in ECDF" style={{maxWidth: '100%', height: 'auto', display: 'block', margin: '1.5rem auto', borderRadius: '8px'}} />

---

## Small Sample Variance
### Quantile Variance
Quantile estimates have variance that depends on:
1. Sample size n
2. The quantile level p
3. The density at the quantile f(Q_p)

**Asymptotic variance:**
```
Var(Q̂_p) ≈ p(1-p) / (n × f(Q_p)²)
```

### Implications
**High variance when:**
- n is small
- p is extreme (near 0 or 1)
- f(Q_p) is small (sparse region)

**Example:**
```
n = 50, p = 0.90

Variance factor = 0.90 × 0.10 / 50 = 0.0018

For p = 0.50:
Variance factor = 0.50 × 0.50 / 50 = 0.0050
```

**The 90th percentile is more variable than the median!**

### Confidence Intervals
**Bootstrap confidence interval for quantiles:**
```python
def quantile_bootstrap_ci(data, p, n_bootstrap=1000, alpha=0.05):
n = len(data)
quantiles = []

for _ in range(n_bootstrap):
sample = np.random.choice(data, size=n, replace=True)
quantiles.append(np.percentile(sample, p * 100))

lower = np.percentile(quantiles, alpha/2 * 100)
upper = np.percentile(quantiles, (1 - alpha/2) * 100)

return lower, upper
```

**Visual Example:**

<img src="/DS-27/quantile_variance.png" alt="Quantile Variance" style={{maxWidth: '100%', height: 'auto', display: 'block', margin: '1.5rem auto', borderRadius: '8px'}} />

---

## Closest Observation Method
### What is It?
The **closest observation method** (Type 1) returns the actual data value closest to the theoretical quantile.

**Formula:**
```
Q(p) = X_(⌈np⌉)
```

### Advantages
1. **Repeatability:** Always returns an actual observation
2. **Stability:** Less sensitive to interpolation choices
3. **Discrete-friendly:** Works well with integer data

### Disadvantages
1. **Discontinuous:** Jumps as p varies
2. **Limited resolution:** Restricted to n possible values
3. **Bias:** May systematically over/underestimate

### Implementation
```python
def quantile_closest(data, p):
"""
Closest observation quantile (Type 1).
"""
sorted_data = np.sort(data)
n = len(data)
index = int(np.ceil(n * p)) - 1  # 0-based index
index = max(0, min(index, n - 1))  # Clamp to valid range
return sorted_data[index]
```

**Visual Example:**

<img src="/DS-27/closest_observation.png" alt="Closest Observation Method" style={{maxWidth: '100%', height: 'auto', display: 'block', margin: '1.5rem auto', borderRadius: '8px'}} />

---

## Repeatability of Thresholds
### Why Repeatability Matters
**Scenario:** You compute a threshold today and again tomorrow.

**Question:** Will you get the same value?

**Factors affecting repeatability:**
1. **Data changes:** New observations added
2. **Tie handling:** Ambiguous quantile definition
3. **Interpolation method:** Different software defaults
4. **Floating-point precision:** Numerical issues

### Strategies for Repeatability
**1. Fix the interpolation method:**
```python
# Always use the same method
threshold = np.percentile(data, 90, interpolation='nearest')
```

**2. Use closest observation:**
```python
# Returns actual data value
threshold = np.percentile(data, 90, interpolation='lower')
```

**3. Round to meaningful precision:**
```python
# Avoid floating-point issues
threshold = round(np.percentile(data, 90), 2)
```

**4. Document the method:**
```python
QUANTILE_CONFIG = {
'method': 'nearest',
'precision': 2,
'version': '1.0'
}
```

**Visual Example:**

<img src="/DS-27/repeatability.png" alt="Threshold Repeatability" style={{maxWidth: '100%', height: 'auto', display: 'block', margin: '1.5rem auto', borderRadius: '8px'}} />

---

## Exercise: Comparing Interpolation Rules
### The Problem
**Given:** A tiny sample: [5, 10, 15, 20, 25] (n = 5)

**Compute:** The 90th percentile under two interpolation rules:
1. Type 1 (nearest/ceiling)
2. Type 7 (linear interpolation)

### Solution
**Data:** [5, 10, 15, 20, 25], n = 5

**Type 1: Nearest (Ceiling)**
```
Index = ⌈n × p⌉ = ⌈5 × 0.90⌉ = ⌈4.5⌉ = 5

Q(0.90) = X_5 = 25
```

**Type 7: Linear Interpolation (Python default)**

Formula: Q(p) = X\_j + (X\_&#123;j+1&#125; - X\_j) × g

Where:
```
(n-1) × p = (5-1) × 0.90 = 3.6

j = ⌊3.6⌋ + 1 = 4 (1-based index)
g = 3.6 - 3 = 0.6

Q(0.90) = X_4 + (X_5 - X_4) × 0.6
= 20 + (25 - 20) × 0.6
= 20 + 3
= 23
```

### Comparison
<table>
<thead>
<tr>
<th>Method</th>
<th>Result</th>
<th>Difference</th>
</tr>
</thead>
<tbody>
<tr>
<td>Type 1 (nearest)</td>
<td>25</td>
<td>-</td>
</tr>
<tr>
<td>Type 7 (linear)</td>
<td>23</td>
<td>-2</td>
</tr>
</tbody>
</table>

**Relative difference:** (25 - 23) / 24 = 8.3%

### Key Observations
1. **Small samples amplify differences:** With n = 5, methods diverge significantly
2. **Type 1 returns actual value:** Always 25 (an observation)
3. **Type 7 interpolates:** 23 is between observations
4. **For thresholds:** Type 1 may be preferred for repeatability

**Visual Example:**

<img src="/DS-27/exercise_comparison.png" alt="Exercise Comparison" style={{maxWidth: '100%', height: 'auto', display: 'block', margin: '1.5rem auto', borderRadius: '8px'}} />

---

## Best Practices for Quantile Estimation
### 1. Choose and Document Your Method
```python
# Configuration
PERCENTILE_METHOD = 'nearest'  # or 'linear', 'lower', etc.
```

### 2. Consider Sample Size
- n < 20: Be cautious, report confidence intervals
- n < 100: Prefer nearest observation
- n > 1000: Interpolation methods converge

### 3. Handle Ties Explicitly
```python
def handle_ties(data, p, method='midpoint'):
# Your tie-handling logic
pass
```

### 4. Use Bootstrap for Uncertainty
```python
lower, upper = quantile_bootstrap_ci(data, 0.90)
print(f"90th percentile: {q:.2f} [{lower:.2f}, {upper:.2f}]")
```

### 5. Round Appropriately
Match precision to data and use case.

### 6. Version Control Thresholds
Track threshold values with their computation method.

---

## Summary Table
<table>
<thead>
<tr>
<th>Issue</th>
<th>Problem</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Ties</strong></td>
<td>Plateau in ECDF</td>
<td>Choose left/right/midpoint rule</td>
</tr>
<tr>
<td><strong>Interpolation</strong></td>
<td>9+ different methods</td>
<td>Fix and document method</td>
</tr>
<tr>
<td><strong>Small n</strong></td>
<td>High variance</td>
<td>Bootstrap CI, be conservative</td>
</tr>
<tr>
<td><strong>Discrete data</strong></td>
<td>Limited resolution</td>
<td>Nearest observation method</td>
</tr>
<tr>
<td><strong>Repeatability</strong></td>
<td>Method differences</td>
<td>Standardize computation</td>
</tr>
</tbody>
</table>

---

## Final Thoughts
Quantile estimation seems simple but has many practical subtleties. For threshold setting:

- **Ties create ambiguity** that must be resolved consistently
- **Small samples increase variance** — report uncertainty
- **Interpolation methods differ** — standardize your choice
- **Repeatability requires discipline** — document everything

**Key Takeaways:**

**ECDF is a step function** with jumps at observations
**Ties create plateaus** where quantiles are non-unique
**9+ interpolation methods** exist—pick one and stick to it
**Variance increases** for extreme quantiles and small samples
**Closest observation** ensures repeatability with actual values
**Bootstrap** provides confidence intervals for quantiles

**Master your quantiles, control your thresholds!**

**Tomorrow's Preview:** Day 28 - Robust Imputation and Numeric Coercion

---