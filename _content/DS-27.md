---
Id: 1027
Title: "Day 27: Quantile Stability, Ties, and Small Samples"
Author: Sughosh P Dixit
Date: "2025-11-27"
Tags: Data Science Quantiles ECDF Interpolation Ties Small Samples Statistics Percentiles
Topic: Data Science
Abstract: "Master practical considerations for computing empirical quantiles. Understand how ties, discrete samples, and different interpolation schemes affect quantile estimates and threshold repeatability."
HeaderImage: /DS-27/quantile_stability_intro.png
isPublished: true
---

# **Day 27: Quantile Stability, Ties, and Small Samples** ğŸ“ŠğŸ”¢

<p style={{fontStyle: 'italic', color: '#666', marginTop: '1rem', textAlign: 'center'}}>Navigate the practical challenges of quantile estimation with ties, small samples, and multiple interpolation methods.</p>

<Lottie animation="analyticsPulse" height={240} width={340} caption="Quantile estimation in real data involves ties, discrete values, and small samplesâ€”all of which affect the stability and repeatability of thresholds." />

<p style={{fontStyle: 'italic', color: '#666', margin: '1rem 0 2rem', textAlign: 'center'}}>When computing percentile thresholds from real data, practical challenges emerge: ties in the data, discrete values, small sample sizes, and different interpolation methods can all affect results.</p>

> ğŸ’¡ **Note:** This article uses technical terms and abbreviations. For definitions, check out the [Key Terms & Glossary](/key) page.

---

## The Problem: Quantiles in Practice ğŸ¯

**Scenario:** You're computing the 90th percentile threshold from transaction data.

**Challenges:**
1. **Ties:** Multiple transactions have the same value
2. **Discrete data:** Values are integers (counts) or categorical
3. **Small samples:** Only 50 observations available
4. **Interpolation:** Different methods give different answers!

**Question:** How do you get stable, repeatable quantile estimates? ğŸ¤”

---

## The Empirical CDF (ECDF) ğŸ“ˆ

### Definition

The **empirical cumulative distribution function** gives the proportion of observations â‰¤ x:

```
FÌ‚_n(x) = (1/n) Ã— |{i : X_i â‰¤ x}|
```

**Properties:**
- Step function (jumps at data points)
- FÌ‚_n(x) âˆˆ [0, 1]
- FÌ‚_n(-âˆ) = 0, FÌ‚_n(âˆ) = 1

### ECDF with Ties

**With ties:** Multiple observations at the same value create larger jumps.

**Example:**
```
Data: [1, 2, 2, 2, 3, 4, 5]  (n = 7)

ECDF:
FÌ‚(1) = 1/7 = 0.143
FÌ‚(2) = 4/7 = 0.571  (3 values = 2, plus 1 below)
FÌ‚(3) = 5/7 = 0.714
FÌ‚(4) = 6/7 = 0.857
FÌ‚(5) = 7/7 = 1.000
```

**Visual Example:**

<img src="/DS-27/ecdf_with_ties.png" alt="ECDF with Ties" style={{maxWidth: '100%', height: 'auto', display: 'block', margin: '1.5rem auto', borderRadius: '8px'}} />

<Lottie animation="robustWorkflow" height={220} width={320} caption="The ECDF forms a staircase pattern, with larger steps where ties occur in the data." />

---

## Quantile Definition: Multiple Methods ğŸ“

### The Quantile Inverse Problem

**Goal:** Find x such that FÌ‚_n(x) = p

**Problem:** ECDF is a step functionâ€”FÌ‚_n(x) = p may have:
- No solution (p falls in a gap)
- Infinite solutions (p falls on a flat step)

### Interpolation Schemes

**There are at least 9 different quantile definitions!**

**Common methods:**

**Type 1: Inverse of ECDF (closest observation)**
```
Q(p) = X_(âŒˆnpâŒ‰)
```

**Type 6: Linear interpolation (Excel)**
```
Q(p) = X_(j) + (X_(j+1) - X_(j)) Ã— (np + 0.5 - j)
where j = âŒŠnp + 0.5âŒ‹
```

**Type 7: Linear interpolation (R/Python default)**
```
Q(p) = X_(j) + (X_(j+1) - X_(j)) Ã— (np + 1 - p - j)
where j = âŒŠ(n-1)p + 1âŒ‹
```

### Why It Matters

**Example: n = 10, find 90th percentile**

Data: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

<table>
<thead>
<tr>
<th>Method</th>
<th>Formula</th>
<th>Result</th>
</tr>
</thead>
<tbody>
<tr>
<td>Type 1</td>
<td>X_(âŒˆ9âŒ‰) = X_9</td>
<td><strong>9</strong></td>
</tr>
<tr>
<td>Type 6</td>
<td>Interpolate</td>
<td><strong>9.05</strong></td>
</tr>
<tr>
<td>Type 7</td>
<td>Interpolate</td>
<td><strong>9.1</strong></td>
</tr>
</tbody>
</table>

**Visual Example:**

<img src="/DS-27/interpolation_methods.png" alt="Interpolation Methods" style={{maxWidth: '100%', height: 'auto', display: 'block', margin: '1.5rem auto', borderRadius: '8px'}} />

---

## Ties: The Plateau Problem ğŸ”ï¸

### What Happens with Ties?

When multiple observations have the same value, the ECDF has a **flat plateau**.

**Problem:** The quantile is **non-unique** at the plateau level.

### Example with Ties

**Data:** [10, 20, 20, 20, 20, 30, 40, 50] (n = 8)

```
ECDF:
FÌ‚(10) = 1/8 = 0.125
FÌ‚(20) = 5/8 = 0.625  â† Plateau from 0.125 to 0.625
FÌ‚(30) = 6/8 = 0.750
FÌ‚(40) = 7/8 = 0.875
FÌ‚(50) = 8/8 = 1.000
```

**What is the 50th percentile?**
- FÌ‚(20) = 0.625 > 0.50
- FÌ‚(10) = 0.125 < 0.50
- Answer: 20 (but could argue for values between 10 and 20)

### Handling Ties

**Strategies:**
1. **Left-continuous:** Q(p) = inf&#123;x : FÌ‚(x) â‰¥ p&#125;
2. **Right-continuous:** Q(p) = inf&#123;x : FÌ‚(x) &gt; p&#125;
3. **Midpoint:** Average of left and right
4. **Random jitter:** Add small noise to break ties

**Visual Example:**

<img src="/DS-27/tie_blocks.png" alt="Tie Blocks in ECDF" style={{maxWidth: '100%', height: 'auto', display: 'block', margin: '1.5rem auto', borderRadius: '8px'}} />

<Lottie animation="breakdownFortress" height={220} width={320} caption="Ties create plateaus in the ECDF where quantile inversion becomes ambiguous." />

---

## Small Sample Variance ğŸ“‰

### Quantile Variance

Quantile estimates have variance that depends on:
1. Sample size n
2. The quantile level p
3. The density at the quantile f(Q_p)

**Asymptotic variance:**
```
Var(QÌ‚_p) â‰ˆ p(1-p) / (n Ã— f(Q_p)Â²)
```

### Implications

**High variance when:**
- n is small
- p is extreme (near 0 or 1)
- f(Q_p) is small (sparse region)

**Example:**
```
n = 50, p = 0.90

Variance factor = 0.90 Ã— 0.10 / 50 = 0.0018

For p = 0.50:
Variance factor = 0.50 Ã— 0.50 / 50 = 0.0050
```

**The 90th percentile is more variable than the median!**

### Confidence Intervals

**Bootstrap confidence interval for quantiles:**
```python
def quantile_bootstrap_ci(data, p, n_bootstrap=1000, alpha=0.05):
    n = len(data)
    quantiles = []
    
    for _ in range(n_bootstrap):
        sample = np.random.choice(data, size=n, replace=True)
        quantiles.append(np.percentile(sample, p * 100))
    
    lower = np.percentile(quantiles, alpha/2 * 100)
    upper = np.percentile(quantiles, (1 - alpha/2) * 100)
    
    return lower, upper
```

**Visual Example:**

<img src="/DS-27/quantile_variance.png" alt="Quantile Variance" style={{maxWidth: '100%', height: 'auto', display: 'block', margin: '1.5rem auto', borderRadius: '8px'}} />

---

## Closest Observation Method ğŸ¯

### What is It?

The **closest observation method** (Type 1) returns the actual data value closest to the theoretical quantile.

**Formula:**
```
Q(p) = X_(âŒˆnpâŒ‰)
```

### Advantages

1. **Repeatability:** Always returns an actual observation
2. **Stability:** Less sensitive to interpolation choices
3. **Discrete-friendly:** Works well with integer data

### Disadvantages

1. **Discontinuous:** Jumps as p varies
2. **Limited resolution:** Restricted to n possible values
3. **Bias:** May systematically over/underestimate

### Implementation

```python
def quantile_closest(data, p):
    """
    Closest observation quantile (Type 1).
    """
    sorted_data = np.sort(data)
    n = len(data)
    index = int(np.ceil(n * p)) - 1  # 0-based index
    index = max(0, min(index, n - 1))  # Clamp to valid range
    return sorted_data[index]
```

**Visual Example:**

<img src="/DS-27/closest_observation.png" alt="Closest Observation Method" style={{maxWidth: '100%', height: 'auto', display: 'block', margin: '1.5rem auto', borderRadius: '8px'}} />

---

## Repeatability of Thresholds ğŸ”„

### Why Repeatability Matters

**Scenario:** You compute a threshold today and again tomorrow.

**Question:** Will you get the same value?

**Factors affecting repeatability:**
1. **Data changes:** New observations added
2. **Tie handling:** Ambiguous quantile definition
3. **Interpolation method:** Different software defaults
4. **Floating-point precision:** Numerical issues

### Strategies for Repeatability

**1. Fix the interpolation method:**
```python
# Always use the same method
threshold = np.percentile(data, 90, interpolation='nearest')
```

**2. Use closest observation:**
```python
# Returns actual data value
threshold = np.percentile(data, 90, interpolation='lower')
```

**3. Round to meaningful precision:**
```python
# Avoid floating-point issues
threshold = round(np.percentile(data, 90), 2)
```

**4. Document the method:**
```python
QUANTILE_CONFIG = {
    'method': 'nearest',
    'precision': 2,
    'version': '1.0'
}
```

**Visual Example:**

<img src="/DS-27/repeatability.png" alt="Threshold Repeatability" style={{maxWidth: '100%', height: 'auto', display: 'block', margin: '1.5rem auto', borderRadius: '8px'}} />

<Lottie animation="classicalVsRobust" height={220} width={320} caption="Consistent quantile computation requires fixed methods, documented choices, and awareness of tie handling." />

---

## Exercise: Comparing Interpolation Rules ğŸ“

### The Problem

**Given:** A tiny sample: [5, 10, 15, 20, 25] (n = 5)

**Compute:** The 90th percentile under two interpolation rules:
1. Type 1 (nearest/ceiling)
2. Type 7 (linear interpolation)

### Solution

**Data:** [5, 10, 15, 20, 25], n = 5

**Type 1: Nearest (Ceiling)**
```
Index = âŒˆn Ã— pâŒ‰ = âŒˆ5 Ã— 0.90âŒ‰ = âŒˆ4.5âŒ‰ = 5

Q(0.90) = X_5 = 25
```

**Type 7: Linear Interpolation (Python default)**

Formula: Q(p) = X\_j + (X\_&#123;j+1&#125; - X\_j) Ã— g

Where:
```
(n-1) Ã— p = (5-1) Ã— 0.90 = 3.6

j = âŒŠ3.6âŒ‹ + 1 = 4 (1-based index)
g = 3.6 - 3 = 0.6

Q(0.90) = X_4 + (X_5 - X_4) Ã— 0.6
        = 20 + (25 - 20) Ã— 0.6
        = 20 + 3
        = 23
```

### Comparison

<table>
<thead>
<tr>
<th>Method</th>
<th>Result</th>
<th>Difference</th>
</tr>
</thead>
<tbody>
<tr>
<td>Type 1 (nearest)</td>
<td>25</td>
<td>-</td>
</tr>
<tr>
<td>Type 7 (linear)</td>
<td>23</td>
<td>-2</td>
</tr>
</tbody>
</table>

**Relative difference:** (25 - 23) / 24 = 8.3%

### Key Observations

1. **Small samples amplify differences:** With n = 5, methods diverge significantly
2. **Type 1 returns actual value:** Always 25 (an observation)
3. **Type 7 interpolates:** 23 is between observations
4. **For thresholds:** Type 1 may be preferred for repeatability

**Visual Example:**

<img src="/DS-27/exercise_comparison.png" alt="Exercise Comparison" style={{maxWidth: '100%', height: 'auto', display: 'block', margin: '1.5rem auto', borderRadius: '8px'}} />

---

## Best Practices for Quantile Estimation âœ…

### 1. Choose and Document Your Method

```python
# Configuration
PERCENTILE_METHOD = 'nearest'  # or 'linear', 'lower', etc.
```

### 2. Consider Sample Size

- n < 20: Be cautious, report confidence intervals
- n < 100: Prefer nearest observation
- n > 1000: Interpolation methods converge

### 3. Handle Ties Explicitly

```python
def handle_ties(data, p, method='midpoint'):
    # Your tie-handling logic
    pass
```

### 4. Use Bootstrap for Uncertainty

```python
lower, upper = quantile_bootstrap_ci(data, 0.90)
print(f"90th percentile: {q:.2f} [{lower:.2f}, {upper:.2f}]")
```

### 5. Round Appropriately

Match precision to data and use case.

### 6. Version Control Thresholds

Track threshold values with their computation method.

---

## Summary Table ğŸ“‹

<table>
<thead>
<tr>
<th>Issue</th>
<th>Problem</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Ties</strong></td>
<td>Plateau in ECDF</td>
<td>Choose left/right/midpoint rule</td>
</tr>
<tr>
<td><strong>Interpolation</strong></td>
<td>9+ different methods</td>
<td>Fix and document method</td>
</tr>
<tr>
<td><strong>Small n</strong></td>
<td>High variance</td>
<td>Bootstrap CI, be conservative</td>
</tr>
<tr>
<td><strong>Discrete data</strong></td>
<td>Limited resolution</td>
<td>Nearest observation method</td>
</tr>
<tr>
<td><strong>Repeatability</strong></td>
<td>Method differences</td>
<td>Standardize computation</td>
</tr>
</tbody>
</table>

---

## Final Thoughts ğŸŒŸ

Quantile estimation seems simple but has many practical subtleties. For threshold setting:

- **Ties create ambiguity** that must be resolved consistently
- **Small samples increase variance** â€” report uncertainty
- **Interpolation methods differ** â€” standardize your choice
- **Repeatability requires discipline** â€” document everything

**Key Takeaways:**

âœ… **ECDF is a step function** with jumps at observations
âœ… **Ties create plateaus** where quantiles are non-unique
âœ… **9+ interpolation methods** existâ€”pick one and stick to it
âœ… **Variance increases** for extreme quantiles and small samples
âœ… **Closest observation** ensures repeatability with actual values
âœ… **Bootstrap** provides confidence intervals for quantiles

**Master your quantiles, control your thresholds!** ğŸ“ŠğŸ¯

**Tomorrow's Preview:** Day 28 - Robust Imputation and Numeric Coercion ğŸ”§ğŸ“Š

---


